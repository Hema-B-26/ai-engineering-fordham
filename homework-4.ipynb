{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ðŸŽ“ **Professor**: Apostolos Filippas\n",
    "\n",
    "### ðŸ“˜ **Class**: AI Engineering\n",
    "\n",
    "### ðŸ“‹ **Homework 4**: Embeddings & Semantic Search\n",
    "\n",
    "### ðŸ“… **Due Date**: Day of Lecture 5, 11:59 PM\n",
    "\n",
    "\n",
    "**Note**: You are not allowed to share the contents of this notebook with anyone outside this class without written permission by the professor.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, you'll build on Homework 3 (BM25 search) by adding **embedding-based semantic search**.\n",
    "\n",
    "You will:\n",
    "1. **Generate embeddings** using both local (Hugging Face) and API (OpenAI) models\n",
    "2. **Implement cosine similarity** from scratch\n",
    "3. **Implement semantic search** from scratch\n",
    "4. **Compare BM25 vs semantic search** using Recall\n",
    "5. **Compare different embedding models** and analyze their differences\n",
    "\n",
    "**Total Points: 95**\n",
    "\n",
    "---\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Complete all tasks by filling in code where you see `# YOUR CODE HERE`\n",
    "- You may use ChatGPT, Claude, documentation, Stack Overflow, etc.\n",
    "- When using external resources, briefly cite them in a comment\n",
    "- Run all cells before submitting to ensure they work\n",
    "\n",
    "**Submission:**\n",
    "1. Create a branch called `homework-4`\n",
    "2. Commit and push your work\n",
    "3. Create a PR and merge to main\n",
    "4. Submit the `.ipynb` file on Blackboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 1: Environment Setup (10 points)\n",
    "\n",
    "### 1a. Imports (5 pts)\n",
    "\n",
    "Import the required libraries and load the WANDS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# ruff: noqa: E402\n",
    "\n",
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import ONLY data loading from helpers\n",
    "#sys.path.append('../scripts') \n",
    "#from helpers import load_wands_products, load_wands_queries, load_wands_labels\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#### used chatGPT to import helpers.py because I was getting errors. \n",
    "helpers_path = os.path.abspath(\"../scripts/helpers.py\")\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"helpers\", helpers_path)\n",
    "helpers = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"helpers\"] = helpers\n",
    "spec.loader.exec_module(helpers)\n",
    "\n",
    "from helpers import load_wands_products, load_wands_queries, load_wands_labels\n",
    "\n",
    "# Embedding libraries - we use these directly\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import litellm\n",
    "\n",
    "# Load environment variables for API keys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "pd.set_option('display.max_colwidth', 80)\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products: 42,994\n",
      "Queries: 480\n",
      "Labels: 233,448\n"
     ]
    }
   ],
   "source": [
    "# Load the WANDS dataset\n",
    "products = load_wands_products()\n",
    "queries = load_wands_queries()\n",
    "labels = load_wands_labels()\n",
    "\n",
    "print(f\"Products: {len(products):,}\")\n",
    "print(f\"Queries: {len(queries):,}\")\n",
    "print(f\"Labels: {len(labels):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Copy BM25 functions from HW3 (5 pts)\n",
    "\n",
    "Copy your BM25 implementation from Homework 3. We'll use it to compare against semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Copy your BM25 functions from Homework 3\n",
    "import Stemmer\n",
    "import string\n",
    "\n",
    "stemmer = Stemmer.Stemmer('english')\n",
    "punct_trans = str.maketrans({key: ' ' for key in string.punctuation})\n",
    "\n",
    "def snowball_tokenize(text: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Tokenize text with Snowball stemming.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to tokenize\n",
    "        \n",
    "    Returns:\n",
    "        List of stemmed tokens\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text is None:\n",
    "        return []\n",
    "    text = str(text).translate(punct_trans)\n",
    "    tokens = text.lower().split()\n",
    "    return [stemmer.stemWord(token) for token in tokens]\n",
    "\n",
    "def build_index(docs: list[str], tokenizer) -> tuple[dict, list[int]]:\n",
    "    \"\"\"\n",
    "    Build an inverted index from a list of documents.\n",
    "    \n",
    "    Args:\n",
    "        docs: List of document strings to index\n",
    "        tokenizer: Function that takes text and returns list of tokens\n",
    "        \n",
    "    Returns:\n",
    "        index: dict mapping term -> {doc_id: term_count}\n",
    "        doc_lengths: list of document lengths (in tokens)\n",
    "    \"\"\"\n",
    "    index = {}\n",
    "    doc_lengths = []\n",
    "    \n",
    "    for doc_id, doc in enumerate(docs):\n",
    "        tokens = tokenizer(doc)\n",
    "        doc_lengths.append(len(tokens))\n",
    "        term_counts = Counter(tokens)\n",
    "        \n",
    "        for term, count in term_counts.items():\n",
    "            if term not in index:\n",
    "                index[term] = {}\n",
    "            index[term][doc_id] = count\n",
    "    \n",
    "    return index, doc_lengths\n",
    "\n",
    "def get_tf(term: str, doc_id: int, index: dict) -> int:\n",
    "    \"\"\"\n",
    "    Get term frequency for a term in a document.\n",
    "    \n",
    "    Args:\n",
    "        term: The term to look up\n",
    "        doc_id: The document ID\n",
    "        index: The inverted index\n",
    "        \n",
    "    Returns:\n",
    "        Term frequency (count), or 0 if not found\n",
    "    \"\"\"\n",
    "    if term in index and doc_id in index[term]:\n",
    "        return index[term][doc_id]\n",
    "    return 0\n",
    "\n",
    "def get_df(term: str, index: dict) -> int:\n",
    "    \"\"\"\n",
    "    Get document frequency for a term.\n",
    "    \n",
    "    Args:\n",
    "        term: The term to look up\n",
    "        index: The inverted index\n",
    "        \n",
    "    Returns:\n",
    "        Number of documents containing the term\n",
    "    \"\"\"\n",
    "    if term in index:\n",
    "        return len(index[term])\n",
    "    return 0\n",
    "\n",
    "def bm25_idf(df: int, num_docs: int) -> float:\n",
    "    \"\"\"\n",
    "    BM25 IDF formula.\n",
    "    \n",
    "    Args:\n",
    "        df: Document frequency\n",
    "        num_docs: Total number of documents\n",
    "        \n",
    "    Returns:\n",
    "        IDF score\n",
    "    \"\"\"\n",
    "    return np.log((num_docs - df + 0.5) / (df + 0.5) + 1)\n",
    "\n",
    "def bm25_tf(tf: int, doc_len: int, avg_doc_len: float, k1: float = 1.2, b: float = 0.75) -> float:\n",
    "    \"\"\"\n",
    "    BM25 TF normalization.\n",
    "    \n",
    "    Args:\n",
    "        tf: Term frequency\n",
    "        doc_len: Document length in tokens\n",
    "        avg_doc_len: Average document length\n",
    "        k1: Saturation parameter (default 1.2)\n",
    "        b: Length normalization (default 0.75)\n",
    "        \n",
    "    Returns:\n",
    "        Normalized TF score\n",
    "    \"\"\"\n",
    "    return (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * doc_len / avg_doc_len))\n",
    "\n",
    "def score_bm25(query: str, index: dict, num_docs: int, doc_lengths: list[int], \n",
    "               tokenizer, k1: float = 1.2, b: float = 0.75) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Score all documents using BM25.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query\n",
    "        index: Inverted index\n",
    "        num_docs: Total number of documents\n",
    "        doc_lengths: List of document lengths\n",
    "        tokenizer: Tokenization function\n",
    "        \n",
    "    Returns:\n",
    "        Array of scores for each document\n",
    "    \"\"\"\n",
    "    query_tokens = tokenizer(query)\n",
    "    scores = np.zeros(num_docs)\n",
    "    avg_doc_len = np.mean(doc_lengths) if doc_lengths else 1.0\n",
    "    \n",
    "    for token in query_tokens:\n",
    "        df = get_df(token, index)\n",
    "        if df == 0:\n",
    "            continue\n",
    "        \n",
    "        idf = bm25_idf(df, num_docs)\n",
    "        \n",
    "        if token in index:\n",
    "            for doc_id, tf in index[token].items():\n",
    "                tf_norm = bm25_tf(tf, doc_lengths[doc_id], avg_doc_len, k1, b)\n",
    "                scores[doc_id] += idf * tf_norm\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def search_products(query: str, products_df: pd.DataFrame, index: dict, \n",
    "                    doc_lengths: list[int], tokenizer, k: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Search products and return top-k results.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query\n",
    "        products_df: DataFrame of products\n",
    "        index: Inverted index\n",
    "        doc_lengths: Document lengths\n",
    "        tokenizer: Tokenization function\n",
    "        k: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with top-k products and scores\n",
    "    \"\"\"\n",
    "    scores = score_bm25(query, index, len(products_df), doc_lengths, tokenizer)\n",
    "    top_k_idx = np.argsort(-scores)[:k]\n",
    "    \n",
    "    results = products_df.iloc[top_k_idx].copy()\n",
    "    results['score'] = scores[top_k_idx]\n",
    "    results['rank'] = range(1, k + 1)\n",
    "    return results\n",
    "\n",
    "print(\"All functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 2: Understanding Embeddings (15 points)\n",
    "\n",
    "### 2a. Load a local model and generate embeddings (5 pts)\n",
    "\n",
    "Use `sentence-transformers` to load a local embedding model and generate embeddings for a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1dd7a24cb543f1bfa44c1d104d953b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 5\n"
     ]
    }
   ],
   "source": [
    "# Load the all-MiniLM-L6-v2 model using SentenceTransformer\n",
    "# Then generate embeddings for each word in the list\n",
    "words = [\"wooden coffee table\", \"oak dining table\", \"red leather sofa\", \"blue area rug\", \"kitchen sink\"]\n",
    "# YOUR CODE HERE\n",
    "# Load model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = model.encode(words, convert_to_numpy=True)\n",
    "# Print the number of embeddings you generated and the dimension of the embeddings\n",
    "print(\"Embedding dimension:\", len(embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Implement cosine similarity and create a similarity matrix (5 pts)\n",
    "\n",
    "Implement cosine similarity from scratch:\n",
    "\n",
    "$$\\text{cosine\\_similarity}(a, b) = \\frac{a \\cdot b}{\\|a\\| \\times \\|b\\|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wooden coffee table</th>\n",
       "      <th>oak dining table</th>\n",
       "      <th>red leather sofa</th>\n",
       "      <th>blue area rug</th>\n",
       "      <th>kitchen sink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wooden coffee table</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.588631</td>\n",
       "      <td>0.370622</td>\n",
       "      <td>0.189486</td>\n",
       "      <td>0.295712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oak dining table</th>\n",
       "      <td>0.588631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.337910</td>\n",
       "      <td>0.249521</td>\n",
       "      <td>0.341410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red leather sofa</th>\n",
       "      <td>0.370622</td>\n",
       "      <td>0.337910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.380311</td>\n",
       "      <td>0.057740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue area rug</th>\n",
       "      <td>0.189486</td>\n",
       "      <td>0.249521</td>\n",
       "      <td>0.380311</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kitchen sink</th>\n",
       "      <td>0.295712</td>\n",
       "      <td>0.341410</td>\n",
       "      <td>0.057740</td>\n",
       "      <td>0.125802</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     wooden coffee table  oak dining table  red leather sofa  \\\n",
       "wooden coffee table             1.000000          0.588631          0.370622   \n",
       "oak dining table                0.588631          1.000000          0.337910   \n",
       "red leather sofa                0.370622          0.337910          1.000000   \n",
       "blue area rug                   0.189486          0.249521          0.380311   \n",
       "kitchen sink                    0.295712          0.341410          0.057740   \n",
       "\n",
       "                     blue area rug  kitchen sink  \n",
       "wooden coffee table       0.189486      0.295712  \n",
       "oak dining table          0.249521      0.341410  \n",
       "red leather sofa          0.380311      0.057740  \n",
       "blue area rug             1.000000      0.125802  \n",
       "kitchen sink              0.125802      1.000000  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement cosine similarity from scratch\n",
    "def cosine_similarity(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "# Create similarity matrix\n",
    "similarity_matrix = np.zeros((len(embeddings), len(embeddings)))\n",
    "for i in range(len(embeddings)):\n",
    "    for j in range(len(embeddings)):\n",
    "        similarity_matrix[i][j] = cosine_similarity(embeddings[i], embeddings[j])\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=words, columns=words)\n",
    "\n",
    "# Display as DataFrame\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Embed using OpenAI API (5 pts)\n",
    "\n",
    "Use `litellm` to get embeddings from OpenAI's API and compare dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI embedding dimension: 1536\n",
      "Local model dimension: 5\n"
     ]
    }
   ],
   "source": [
    "# Use litellm to get an embedding from OpenAI's text-embedding-3-small model\n",
    "# Compare the dimension with the local model\n",
    "response = litellm.embedding(model=\"text-embedding-3-small\", input=[\"wooden coffee table\"])\n",
    "openai_embedding = np.array(response.data[0][\"embedding\"])\n",
    "#print(response.choices[0].message.content)\n",
    "print(\"OpenAI embedding dimension:\", len(openai_embedding))\n",
    "print(\"Local model dimension:\", len(embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 3: Batch Embedding Products (20 points)\n",
    "\n",
    "### 3a. Embed a product sample (10 pts)\n",
    "\n",
    "Create a combined text field and embed 5,000 products using the local model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a consistent sample\n",
    "products_sample = products.sample(n=5000, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99e2f38039f4d9d80ddea850e3637f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (5000, 384)\n"
     ]
    }
   ],
   "source": [
    "# Create a combined text field (product_name + product_class)\n",
    "# Then embed all products using model.encode()\n",
    "# YOUR CODE HERE\n",
    "products_sample[\"combined_text\"] = ( products_sample[\"product_name\"].fillna(\"\") + \" \" +\n",
    "products_sample[\"product_class\"].fillna(\"\"))\n",
    "product_embeddings = model.encode( products_sample[\"combined_text\"].tolist(), batch_size=64, show_progress_bar=True )\n",
    "print(\"Embedding shape:\", product_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Save and load embeddings (5 pts)\n",
    "\n",
    "Save embeddings to a `.npy` file so you don't have to recompute them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings match: True\n"
     ]
    }
   ],
   "source": [
    "# Save embeddings to ../temp/hw4_embeddings.npy\n",
    "np.save(\"/Users/hema/ai-engineering-fordham/temp/hw4_embeddings.npy\", product_embeddings)\n",
    "# Save products_sample to ../temp/hw4_products.csv\n",
    "products_sample.to_csv(\"/Users/hema/ai-engineering-fordham/temp/hw4_products.csv\", index=False)\n",
    "# Then load them back and verify they match\n",
    "loaded_embeddings = np.load(\"/Users/hema/ai-engineering-fordham/temp/hw4_embeddings.npy\")\n",
    "loaded_products = pd.read_csv(\"/Users/hema/ai-engineering-fordham/temp/hw4_products.csv\")\n",
    "print(\"Embeddings match:\", np.array_equal(product_embeddings, loaded_embeddings))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Cost estimation (5 pts)\n",
    "\n",
    "Estimate the cost to embed all 43K products using OpenAI's API.\n",
    "\n",
    "**Pricing**: text-embedding-3-small costs ~$0.02 per 1 million tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens in sample: 65077\n",
      "Estimated cost to embed 43K products: $ 0.01\n"
     ]
    }
   ],
   "source": [
    "# Use tiktoken to count actual tokens in the sample\n",
    "\n",
    "##### used chatGPT to figure out how to use tiktoken\n",
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"text-embedding-3-small\")\n",
    "sample_text = products_sample[\"combined_text\"].tolist()\n",
    "total_tokens = 0\n",
    "for text in sample_text:\n",
    "    total_tokens += len(encoding.encode(text))\n",
    "print(\"Total tokens in sample:\", total_tokens)\n",
    "\n",
    "# Then extrapolate to estimate cost for the full dataset\n",
    "avg_tokens = total_tokens / 5000\n",
    "estimated_total_tokens = avg_tokens * 43000\n",
    "cost_per_million = 0.02\n",
    "estimated_cost = (estimated_total_tokens / 1_000_000) * cost_per_million\n",
    "print(\"Estimated cost to embed 43K products: $\", round(estimated_cost, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 4: Semantic Search (25 points)\n",
    "\n",
    "### 4a. Implement semantic search (15 pts)\n",
    "\n",
    "Implement a semantic search function from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement batch cosine similarity for efficiency\n",
    "def batch_cosine_similarity(query_embedding, product_embeddings):\n",
    "    query_norm = query_embedding / np.linalg.norm(query_embedding)\n",
    "    product_norms = product_embeddings / np.linalg.norm(product_embeddings, axis=1, keepdims=True)\n",
    "    similarities = np.dot(product_norms, query_norm)\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement semantic search\n",
    "def semantic_search(query, model, product_embeddings, products_df, top_k=10):\n",
    "    query_embedding = model.encode(query)\n",
    "    similarities = batch_cosine_similarity(query_embedding, product_embeddings)\n",
    "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "    return products_df.iloc[top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_class</th>\n",
       "      <th>category_hierarchy</th>\n",
       "      <th>product_description</th>\n",
       "      <th>product_features</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>review_count</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>38543</td>\n",
       "      <td>sofa bed with ottoman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Furniture / Living Room Furniture / Sofas</td>\n",
       "      <td>create a cozy spot in your living room with this sofa bed . the sofa bed and...</td>\n",
       "      <td>seatwidth-sidetoside:61|overallheight-toptobottom:36|seatfillmaterial : foam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sofa bed with ottoman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>13047</td>\n",
       "      <td>arshleen patio sofa with cushions</td>\n",
       "      <td>Patio Sofas</td>\n",
       "      <td>Outdoor / Outdoor &amp; Patio Furniture / Outdoor Seating &amp; Patio Chairs / Patio...</td>\n",
       "      <td>the outdoor patio furniture wicker rattan sofa seat with olefin cushions are...</td>\n",
       "      <td>piecesincluded : |levelofassembly : none|seatingcapacity:3|cushioncoverclosu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>arshleen patio sofa with cushions Patio Sofas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3032</th>\n",
       "      <td>20279</td>\n",
       "      <td>simge patio sofa with cushions</td>\n",
       "      <td>Patio Sofas</td>\n",
       "      <td>Outdoor / Outdoor &amp; Patio Furniture / Outdoor Seating &amp; Patio Chairs / Patio...</td>\n",
       "      <td>this sofa is a beautiful example of today â€™ s casual contemporary styling . ...</td>\n",
       "      <td>armheight-floortoarm:25.19|cushioncovermaterial : olefin|cushioncoverclosure...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>simge patio sofa with cushions Patio Sofas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>9687</td>\n",
       "      <td>kendall sectional sofa with ottoman</td>\n",
       "      <td>Sectionals</td>\n",
       "      <td>Furniture / Living Room Furniture / Sectionals</td>\n",
       "      <td>this sectional has a simple but elegant contemporary look that will combo we...</td>\n",
       "      <td>ottomandepth-fronttoback:23|upholsterycolor : gray|orientation : left hand f...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>kendall sectional sofa with ottoman Sectionals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>28692</td>\n",
       "      <td>yland patio sofa with cushions</td>\n",
       "      <td>Patio Sofas</td>\n",
       "      <td>Outdoor / Outdoor &amp; Patio Furniture / Outdoor Seating &amp; Patio Chairs / Patio...</td>\n",
       "      <td>build a daybed for daydreaming , a lounge sofa for night-time entertaining ....</td>\n",
       "      <td>fullorlimitedwarranty : full|style : coastal|framematerial : wicker/rattan|s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yland patio sofa with cushions Patio Sofas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>27404</td>\n",
       "      <td>baeten patio sofa with cushions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Outdoor / Outdoor &amp; Patio Furniture / Outdoor Seating &amp; Patio Chairs / Patio...</td>\n",
       "      <td>5 piece cushioned patio set , which in modern designs , are constructed from...</td>\n",
       "      <td>dssecondaryproductstyle : transitional modern|piecesincluded:5|warrantylengt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>baeten patio sofa with cushions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3371</th>\n",
       "      <td>14295</td>\n",
       "      <td>samuel 91 '' velvet flared arm sofa</td>\n",
       "      <td>Sofas</td>\n",
       "      <td>Furniture / Living Room Furniture / Sofas</td>\n",
       "      <td>surround yourself in elegance as you relax against the various upholsteries ...</td>\n",
       "      <td>dssecondaryproductstyle : contemporary glam|overallproductweight:131|pattern...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>samuel 91 '' velvet flared arm sofa Sofas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4768</th>\n",
       "      <td>41382</td>\n",
       "      <td>castilloux patio sofa with cushions</td>\n",
       "      <td>Patio Sofas</td>\n",
       "      <td>Outdoor / Outdoor &amp; Patio Furniture / Outdoor Seating &amp; Patio Chairs / Patio...</td>\n",
       "      <td>enjoy al fresco meals on your patio or porch with this seven-piece outdoor d...</td>\n",
       "      <td>supplierintendedandapproveduse : non residential use|framecolor : gray|seati...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>castilloux patio sofa with cushions Patio Sofas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4741</th>\n",
       "      <td>18969</td>\n",
       "      <td>94 '' square arm sofa with reversible cushions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Furniture / Living Room Furniture / Sofas</td>\n",
       "      <td>this sofa is the biggest , deepest , softest , most comfortable one-piece so...</td>\n",
       "      <td>legcolor : black|seatdepthsd : extra deep ( over 35 '' ) |backfillmaterial :...</td>\n",
       "      <td>282.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>208.0</td>\n",
       "      <td>94 '' square arm sofa with reversible cushions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>22118</td>\n",
       "      <td>abrish patio sectional with cushions</td>\n",
       "      <td>Patio Sofas</td>\n",
       "      <td>Outdoor / Outdoor &amp; Patio Furniture / Outdoor Seating &amp; Patio Chairs / Patio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>framedurability : rust resistant|cushioncoverclosuremethod : zipper|dsprimar...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>abrish patio sectional with cushions Patio Sofas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      product_id                                    product_name  \\\n",
       "723        38543                           sofa bed with ottoman   \n",
       "611        13047               arshleen patio sofa with cushions   \n",
       "3032       20279                  simge patio sofa with cushions   \n",
       "2120        9687             kendall sectional sofa with ottoman   \n",
       "2631       28692                  yland patio sofa with cushions   \n",
       "2736       27404                 baeten patio sofa with cushions   \n",
       "3371       14295             samuel 91 '' velvet flared arm sofa   \n",
       "4768       41382             castilloux patio sofa with cushions   \n",
       "4741       18969  94 '' square arm sofa with reversible cushions   \n",
       "1668       22118            abrish patio sectional with cushions   \n",
       "\n",
       "     product_class  \\\n",
       "723            NaN   \n",
       "611    Patio Sofas   \n",
       "3032   Patio Sofas   \n",
       "2120    Sectionals   \n",
       "2631   Patio Sofas   \n",
       "2736           NaN   \n",
       "3371         Sofas   \n",
       "4768   Patio Sofas   \n",
       "4741           NaN   \n",
       "1668   Patio Sofas   \n",
       "\n",
       "                                                                   category_hierarchy  \\\n",
       "723                                         Furniture / Living Room Furniture / Sofas   \n",
       "611   Outdoor / Outdoor & Patio Furniture / Outdoor Seating & Patio Chairs / Patio...   \n",
       "3032  Outdoor / Outdoor & Patio Furniture / Outdoor Seating & Patio Chairs / Patio...   \n",
       "2120                                   Furniture / Living Room Furniture / Sectionals   \n",
       "2631  Outdoor / Outdoor & Patio Furniture / Outdoor Seating & Patio Chairs / Patio...   \n",
       "2736  Outdoor / Outdoor & Patio Furniture / Outdoor Seating & Patio Chairs / Patio...   \n",
       "3371                                        Furniture / Living Room Furniture / Sofas   \n",
       "4768  Outdoor / Outdoor & Patio Furniture / Outdoor Seating & Patio Chairs / Patio...   \n",
       "4741                                        Furniture / Living Room Furniture / Sofas   \n",
       "1668  Outdoor / Outdoor & Patio Furniture / Outdoor Seating & Patio Chairs / Patio...   \n",
       "\n",
       "                                                                  product_description  \\\n",
       "723   create a cozy spot in your living room with this sofa bed . the sofa bed and...   \n",
       "611   the outdoor patio furniture wicker rattan sofa seat with olefin cushions are...   \n",
       "3032  this sofa is a beautiful example of today â€™ s casual contemporary styling . ...   \n",
       "2120  this sectional has a simple but elegant contemporary look that will combo we...   \n",
       "2631  build a daybed for daydreaming , a lounge sofa for night-time entertaining ....   \n",
       "2736  5 piece cushioned patio set , which in modern designs , are constructed from...   \n",
       "3371  surround yourself in elegance as you relax against the various upholsteries ...   \n",
       "4768  enjoy al fresco meals on your patio or porch with this seven-piece outdoor d...   \n",
       "4741  this sofa is the biggest , deepest , softest , most comfortable one-piece so...   \n",
       "1668                                                                              NaN   \n",
       "\n",
       "                                                                     product_features  \\\n",
       "723   seatwidth-sidetoside:61|overallheight-toptobottom:36|seatfillmaterial : foam...   \n",
       "611   piecesincluded : |levelofassembly : none|seatingcapacity:3|cushioncoverclosu...   \n",
       "3032  armheight-floortoarm:25.19|cushioncovermaterial : olefin|cushioncoverclosure...   \n",
       "2120  ottomandepth-fronttoback:23|upholsterycolor : gray|orientation : left hand f...   \n",
       "2631  fullorlimitedwarranty : full|style : coastal|framematerial : wicker/rattan|s...   \n",
       "2736  dssecondaryproductstyle : transitional modern|piecesincluded:5|warrantylengt...   \n",
       "3371  dssecondaryproductstyle : contemporary glam|overallproductweight:131|pattern...   \n",
       "4768  supplierintendedandapproveduse : non residential use|framecolor : gray|seati...   \n",
       "4741  legcolor : black|seatdepthsd : extra deep ( over 35 '' ) |backfillmaterial :...   \n",
       "1668  framedurability : rust resistant|cushioncoverclosuremethod : zipper|dsprimar...   \n",
       "\n",
       "      rating_count  average_rating  review_count  \\\n",
       "723            NaN             NaN           NaN   \n",
       "611            NaN             NaN           NaN   \n",
       "3032           NaN             NaN           NaN   \n",
       "2120          10.0             4.0           9.0   \n",
       "2631           NaN             NaN           NaN   \n",
       "2736           NaN             NaN           NaN   \n",
       "3371           NaN             NaN           NaN   \n",
       "4768          12.0             4.0          11.0   \n",
       "4741         282.0             4.5         208.0   \n",
       "1668           6.0             4.0           6.0   \n",
       "\n",
       "                                         combined_text  \n",
       "723                             sofa bed with ottoman   \n",
       "611      arshleen patio sofa with cushions Patio Sofas  \n",
       "3032        simge patio sofa with cushions Patio Sofas  \n",
       "2120    kendall sectional sofa with ottoman Sectionals  \n",
       "2631        yland patio sofa with cushions Patio Sofas  \n",
       "2736                  baeten patio sofa with cushions   \n",
       "3371         samuel 91 '' velvet flared arm sofa Sofas  \n",
       "4768   castilloux patio sofa with cushions Patio Sofas  \n",
       "4741   94 '' square arm sofa with reversible cushions   \n",
       "1668  abrish patio sectional with cushions Patio Sofas  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test semantic search\n",
    "semantic_search(\"comfortable sofa\", model, product_embeddings, products_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Evaluate and compare BM25 vs semantic search (10 pts)\n",
    "\n",
    "Implement Recall@k and compare the two search methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Recall@k\n",
    "def recall_at_k(relevant_items, retrieved_items, k=10):\n",
    "    retrieved_at_k = retrieved_items[:k]\n",
    "    relevant_set = set(relevant_items)\n",
    "    hits = 0\n",
    "    for item in retrieved_at_k:\n",
    "        if item in relevant_set:\n",
    "            hits += 1    \n",
    "    return hits / len(relevant_set) if len(relevant_set) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build BM25 index for comparison\n",
    "# Filter queries to those with products in our sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate both BM25 and semantic search on all queries\n",
    "# Calculate Recall@10 for each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 5: Compare Embedding Models (20 points)\n",
    "\n",
    "### 5a. Embed products with two different models (10 pts)\n",
    "\n",
    "Compare embeddings from:\n",
    "- `BAAI/bge-base-en-v1.5`\n",
    "- `sentence-transformers/all-mpnet-base-v2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6144ad6011ea4382846d3b6ea26514d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: BAAI/bge-base-en-v1.5\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b905ee4a1634d269151c1d0cfe36e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mMPNetModel LOAD REPORT\u001b[0m from: sentence-transformers/all-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load the two embedding models\n",
    "bge_model = SentenceTransformer(\"BAAI/bge-base-en-v1.5\")\n",
    "mpnet_model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed products with both models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b. Compare search results between models (10 pts)\n",
    "\n",
    "Evaluate both models on the same queries and analyze differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results for specific queries\n",
    "test_queries = [\"comfortable sofa\", \"star wars rug\", \"modern coffee table\"]\n",
    "# add more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison with a scatter plot\n",
    "# X-axis: BGE Recall@10, Y-axis: MPNet Recall@10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 6: Git Submission (5 points)\n",
    "\n",
    "Submit your work using the Git workflow:\n",
    "\n",
    "- [ ] Create a new branch called `homework-4`\n",
    "- [ ] Commit your work with a meaningful message\n",
    "- [ ] Push to GitHub\n",
    "- [ ] Create a Pull Request\n",
    "- [ ] Merge the PR to main\n",
    "- [ ] Submit the `.ipynb` file on Blackboard\n",
    "\n",
    "The TA will verify your submission by checking the merged PR on GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
